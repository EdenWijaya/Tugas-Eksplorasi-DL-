# -*- coding: utf-8 -*-
"""Per 6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EXzPlcU2GxJPYZPaWxIaczse2xMzdQyg
"""

!unzip IF25-4041-dataset.zip

import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split

import pandas as pd
from PIL import Image
import os
from tqdm.auto import tqdm
import matplotlib.pyplot as plt

# Cek ketersediaan device
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Menggunakan device: {device}")

# Definisikan Custom Dataset Class
class IndonesianFoodDataset(Dataset):
    def __init__(self, annotations_df, img_dir, transform=None):
        self.annotations = annotations_df
        self.img_dir = img_dir
        self.transform = transform
        self.class_to_idx = {label: i for i, label in enumerate(sorted(self.annotations['label'].unique()))}
        self.idx_to_class = {i: label for label, i in self.class_to_idx.items()}

    def __len__(self):
        return len(self.annotations)

    def __getitem__(self, idx):
        img_filename = self.annotations.iloc[idx, 0]
        img_path = os.path.join(self.img_dir, img_filename)
        image = Image.open(img_path).convert("RGB")
        label_name = self.annotations.iloc[idx, 1]
        label = self.class_to_idx[label_name]
        if self.transform:
            image = self.transform(image)
        return image, label

# Definisikan Transformasi & Augmentasi
IMAGE_SIZE = 224
train_transforms = transforms.Compose([
    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(15),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
val_transforms = transforms.Compose([
    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Baca dan bagi data
IMAGE_DIR_PATH = 'train'
df = pd.read_csv('train.csv')
train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])

# Buat instance Dataset
train_dataset = IndonesianFoodDataset(train_df, IMAGE_DIR_PATH, train_transforms)
val_dataset = IndonesianFoodDataset(val_df, IMAGE_DIR_PATH, val_transforms)

# Buat DataLoader
BATCH_SIZE = 32
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)

print("✅ Persiapan data selesai. DataLoader siap digunakan.")

# Blok bangunan untuk Plain Network (tanpa skip connection)
class PlainBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1):
        super(PlainBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
    def forward(self, x):
        out = self.relu(self.bn1(self.conv1(x)))
        out = self.relu(self.bn2(self.conv2(out)))
        return out

# Arsitektur PlainNet-34 secara keseluruhan
class PlainNet(nn.Module):
    def __init__(self, block, num_blocks, num_classes=5):
        super(PlainNet, self).__init__()
        self.in_channels = 64
        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)
        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)
        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)
        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(512, num_classes)
    def _make_layer(self, block, out_channels, num_blocks, stride):
        strides = [stride] + [1] * (num_blocks - 1)
        layers = []
        for s in strides:
            layers.append(block(self.in_channels, out_channels, s))
            self.in_channels = out_channels
        return nn.Sequential(*layers)
    def forward(self, x):
        out = self.relu(self.bn1(self.conv1(x)))
        out = self.maxpool(out)
        out = self.layer1(out); out = self.layer2(out); out = self.layer3(out); out = self.layer4(out)
        out = self.avgpool(out)
        out = torch.flatten(out, 1)
        out = self.fc(out)
        return out

def Plain34(num_classes=5):
    return PlainNet(PlainBlock, [3, 4, 6, 3], num_classes=num_classes)

print("✅ Arsitektur Plain-34 berhasil didefinisikan.")

def train_model(model, criterion, optimizer, num_epochs=10):
    best_val_accuracy = 0.0
    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}

    for epoch in range(num_epochs):
        # Training
        model.train()
        train_loss, train_corrects = 0.0, 0
        for inputs, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs} [Training]"):
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
            _, preds = torch.max(outputs, 1)
            train_corrects += torch.sum(preds == labels.data)

        # Validation
        model.eval()
        val_loss, val_corrects = 0.0, 0
        with torch.no_grad():
            for inputs, labels in tqdm(val_loader, desc=f"Epoch {epoch+1}/{num_epochs} [Validasi]"):
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
                _, preds = torch.max(outputs, 1)
                val_corrects += torch.sum(preds == labels.data)

        # Calculate and print results
        avg_train_loss = train_loss / len(train_loader.dataset)
        avg_train_acc = train_corrects.double() / len(train_loader.dataset)
        avg_val_loss = val_loss / len(val_loader.dataset)
        avg_val_acc = val_corrects.double() / len(val_loader.dataset)

        history['train_loss'].append(avg_train_loss); history['train_acc'].append(avg_train_acc.item())
        history['val_loss'].append(avg_val_loss); history['val_acc'].append(avg_val_acc.item())

        print(f"Epoch {epoch+1} -> Train Loss: {avg_train_loss:.4f}, Acc: {avg_train_acc:.4f} | Val Loss: {avg_val_loss:.4f}, Acc: {avg_val_acc:.4f}")

    return history

print("✅ Fungsi 'train_model' siap digunakan.")

print("--- TAHAP 1: MELATIH PLAIN-34 NETWORK (DARI NOL) ---")
model_plain = Plain34(num_classes=5).to(device)
criterion = nn.CrossEntropyLoss()
optimizer_plain = torch.optim.Adam(model_plain.parameters(), lr=0.001)

history_plain = train_model(model_plain, criterion, optimizer_plain, num_epochs=10)

print("TAHAP 2: MELATIH RESNET-34")
model_resnet = models.resnet34(weights=None, num_classes=5).to(device)
criterion = nn.CrossEntropyLoss() # Bisa didefinisikan ulang atau tidak
optimizer_resnet = torch.optim.Adam(model_resnet.parameters(), lr=0.001)

history_resnet = train_model(model_resnet, criterion, optimizer_resnet, num_epochs=10)

# Ambil akurasi validasi terbaik dari history
best_plain_acc = max(history_plain['val_acc'])
best_resnet_acc = max(history_resnet['val_acc'])

print("\n--- PERBANDINGAN HASIL AKHIR ---")
print(f"Akurasi Validasi Terbaik Plain-34: {best_plain_acc:.4f}")
print(f"Akurasi Validasi Terbaik ResNet-34: {best_resnet_acc:.4f}")

# Plotting hasil
plt.figure(figsize=(10, 5))
plt.plot(history_plain['val_acc'], label='Plain-34 Val Accuracy', marker='o')
plt.plot(history_resnet['val_acc'], label='ResNet-34 Val Accuracy', marker='x')
plt.title('Perbandingan Akurasi Validasi: Plain-34 vs ResNet-34')
plt.xlabel('Epoch')
plt.ylabel('Akurasi')
plt.legend()
plt.grid(True)
plt.show()